
import numpy as np


class MFM_generator():
    """Generate synthetic cluster distributions using the Mixture of Finite Mixture (MFM) generative model

    The number of data points ~ Uniform(Nmin, Nmax)
    The cluster assignments is produced by a MFM generative model: 
    https://doi.org/10.1080/01621459.2016.1255636
    Here the number of clusters is generated by a one-shifted Poisson distribution
    """

    def __init__(self, Nmin, Nmax, maxK=None, poisson_lambda=2, dirichlet_alpha=1):
        """Set MFM parameters
        Args:
            Nmin: the minimum number of synthetic data points 
            Nmax: the maximum number of synthetic data points
            maxK: the maximum number of synthetic clusters (clip the long tail of large K)
            poisson_lambda: The lambda parameter of shifted Poisson distribution (prior for the number of clusters)
            dirichlet_alpha: The alpha parameter of Dirichlet distribution (prior for cluster proportions)
        """
        assert Nmin > 0 and Nmax > Nmin
        self.Nmin = Nmin
        self.Nmax = Nmax
        self.maxK = maxK
        self.poisson_lambda = poisson_lambda
        self.dirichlet_alpha = dirichlet_alpha

    def generate(self, N=None):
        """Generate synthetic cluster assignments

        If N is given, generated a fixed number of data points with cluster assignments
        If N is None, generate a random number of data points in the range of [Nmin, Nmax] with cluster assignments 

        Args:
            N: int or None
        Returns:
            clusters: a numpy array of shape (N,) of cluster assignments
            N: total number of data points
            K: total number of distinct clusters 
        """
        if N is None:
            N = np.random.randint(self.Nmin, self.Nmax)

        # K ~ Pk(k) = Poisson(k | lambda) + 1, lambda > 0
        K_prior = np.random.poisson(self.poisson_lambda) + 1
        if self.maxK is not None:
            while K_prior > self.maxK:
                K_prior = np.random.poisson(self.poisson_lambda) + 1

        # (pi_1, ..., pi_k) ~ Dirichlet(alpha_1, ..., alpha_k)
        cluster_prob = np.random.dirichlet(
            np.ones(K_prior) * self.dirichlet_alpha)

        # Z_1, ..., Z_n ~ Cat(pi_1, ..., pi_k)
        cluster_assignments = np.random.choice(
            np.arange(1, K_prior+1), size=N, p=cluster_prob)
        # if some clusters have low prob, they might not show up in the samples.
        # Sometimes K_prior != K_sampled

        cluster_ids, cluster_count = np.unique(
            cluster_assignments, return_counts=True)
        K = len(cluster_count)
        clusters = np.zeros(N, dtype=int)
        for i in range(K):
            clusters[i+1] = cluster_count[i]
        return clusters, N, K


class CRP_generator():
    """Generate synthetic cluster distributions using the Chinese Restaurant Process (CRP) generative model

    The number of data points ~ Uniform(Nmin, Nmax)
    The cluster assignments is produced by a CRP generative model: 
    """

    def __init__(self, Nmin, Nmax, maxK=None, alpha=0.7):
        """Set CRP parameters
        Args:
            Nmin: the minimum number of synthetic data points 
            Nmax: the maximum number of synthetic data points
            maxK: the maximum number of synthetic clusters (clip the long tail of large K)
            alpha: the dispersion parameter of CRP
        """
        assert Nmin > 0 and Nmax > Nmin
        self.Nmin = Nmin
        self.Nmax = Nmax
        self.maxK = maxK
        self.alpha = alpha

    def generate(self, N=None):
        """Generate synthetic cluster assignments

        If N is given, generated a fixed number of data points with cluster assignments
        If N is None, generate a random number of data points in the range of [Nmin, Nmax] with cluster assignments 

        Args:
            N: int or None
        Returns:
            clusters: a numpy array of shape (N,) of cluster assignments
            N: total number of data points
            K: total number of distinct clusters 
        """
        keep = True
        while keep:
            if N is None:
                N = np.random.randint(self.Nmin, self.Nmax)

            clusters = np.zeros(N+2)  # 0...N,N+1  how many data points in each cluster
            clusters[0] = 0  # placeholder 
            clusters[1] = 1  # first cluster. After this, fill the array with cumsum
            clusters[2] = self.alpha  # dispersion
            index_new = 2  # the next unassigned cluster ID

            # loop over N-1 data points because the first one was assigned already to cluster 1
            for n in range(N-1):
                p = clusters / clusters.sum()
                # random draw from 0...n_clust+1
                z = np.argmax(np.random.multinomial(1, p))
                if z < index_new:  # existing clusters
                    clusters[z] += 1
                else:  # new cluster
                    clusters[index_new] = 1
                    index_new += 1
                    # the next new cluster, with prob = alpha/(n_samples + alpha)
                    clusters[index_new] = self.alpha

            clusters[index_new] = 0
            clusters = clusters.astype(np.int32)  

            N = int(np.sum(clusters))
            K = np.sum(clusters > 0)
            keep = (self.maxK is not None and K > self.maxK)

        return clusters, N, K
